% !TeX root = main.tex
% !TeX spellcheck = en-US
% !TeX encoding = utf8


\chapter{Conclusion}
\label{chap:conclusion}

\glsresetall

In this thesis we successfully applied methods from \gls{hpo} to tune the parameters of the \gls{hsppbo} metaheuristic algorithm to solve the \gls{dtsp}. 
Not only did the parameters obtained by \gls{hpo} perform incredibly well in the dynamic phase of the \gls{dtsp}, but the static performance, just before the problem was changed, also showed admirable performance, especially when compared to a standard set of reference parameters for \gls{hsppbo}.

By planning and implementing all aspects necessary to answer the research questions, a completely new framework was derived, the \gls{xfopt}. Its main goal is to combine a variety of \gls{hpo} methods, such as \gls{rs}, \gls{bo}, and \gls{gbrt}, with the \gls{hsppbo} metaheuristic, all implemented in the \texttt{Python} programming language. Moreover, it provides modularity and interfaces for each of the main modules, the problem, the optimizer, and the metaheuristic, allowing easy extensibility and ensuring potential future development based on the \gls{xfopt} framework. 
In light of the results discussed, it stands as a promising example of the potential that lies in the combination of \gls{hpo} and metaheuristics.

The work done to plan out the most efficient way to perform all the necessary experiments and to analyze the huge amount of data obtained also proved to be worthwhile. The ten \gls{tsp} instances and the three dynamic intensities tested provided a well-rounded subset of problems. While the partitioning of the \gls{tsp} instances from the  \texttt{TSPLIB} benchmark set into structural groups was ultimately not observed in the data analyzed, the goal of using disjoint subsets to reduce the number of experiments was still achieved, with all groups successfully generalizing their parameter sets to their larger counterparts. The parameter constrains postulated and used in the optimization process also proved to be correct, with the exception of $\beta$, which showed a clear ceiling effect. 

The the three parts of the experiments that were conducted all successfully served their purpose of answering the research questions, and during the data analysis no data was felt to be missing, due in large part to the automation of the process using a logging module that captured all the raw data outputs of the processes, and an analysis module that was able to calculate complex tabular results as well as visualize large amounts of data with different aggregations. However, due to the many repetitions of the \gls{hpo} procedure, and despite using two servers in parallel to compute the workload, the experiments took almost three months to complete.

The first research question, the choice of the ideal \gls{hpo} method for the \gls{hsppbo} metaheuristic, was answered in the first part of the results chapter. The arguments provided by convergence plots, \gls{auc} and minimum solution quality metrics, and statistical tests made it clear that \gls{gbrt} was the best choice for \gls{hsppbo}, since it almost always found the best solutions, while converging to them the fastest out of the the four methods compared. Furthermore, \gls{gp} and \gls{et} also showed very promising performance, with \gls{gp} in particular, excelling in \gls{tsp} instances of larger dimension.

The second question of what these best parameter sets look like was answered by the second part of the experiments. Here the results were more ambivalent. Although well-performing parameter sets were found for all specific combinations of problem instance and dynamic intensity, no clear recommendations for parameter values  could be made under most considerations. Except for $\alpha$ and $\beta$, which also seemed to be the most important parameters for the trained \gls{gbrt} surrogate model, and the favored use of the partial reset as the change handling procedure, only improved parameter value ranges were given for the remaining parameters, the three weights, and the detection threshold. In addition, no significant zero order correlation was found between these parameters. 

In the final results chapter, all of these findings were combined - using the best \gls{hpo} method to generate the best parameter values for each combination of problem instance and dynamic intensity - and compared to a well-performing reference parameter set. In terms of solution quality, the \gls{hpo} parameters showed excellent results across all problem descriptions and throughout the runtime. However, it was found that this good solution quality was not due to the correct detection of dynamic changes, but was achieved despite their absence. The reference parameter set outperformed the \gls{hpo} parameters in every discipline regarding dynamic detection, which was explained by either too low or too high choices for the detection threshold $\theta$.

In summary, \gls{hpo} has great potential for tuning the parameters of \gls{hsppbo} and possibly metaheuristics in general. Different optimization methods have different effects on the resulting parameter values and on the problems on which they are obtained on. No single set of parameter values can be recommended to solve all \gls{dtsp} problem descriptions, be they instance or dynamic. However, through the efficient application of \gls{hpo} methods, such a general-purpose parameter set can easily be replaced by a parameter set specifically tuned for a given problem. In the case of \gls{hsppbo}, it is debatable whether good performance on the \gls{dtsp} should be achieved by constructing highly greedy-influenced \glspl{sce}, or by correct detection of dynamic events, and also which parameters influence the solution quality the most.

\section{Future Work}

On many occasions throughout the thesis, thoughts were given about possible future work and research. 
In order to further improve the solution quality, new parameter value ranges and fixed value recommendations were presented (see \cref{chap:param-recommend}), which are an ideal starting point for new experiments with any kind of \gls{hpo} method. In this context, the good performance of the \gls{gp} method for \gls{tsp} instances of larger dimension ($>150$) could be further analyzed, especially in comparison with \gls{gbrt}. Since the optimization results focused on the parameters that lead to the best solution quality, the experiments were also prepare with this goal in mind. This raises two interesting topics that could not be answered with the available data. First, the tuning of the \gls{hpo} process itself could significantly reduce the time needed for a parameter set. Thus, experiments should be conducted on the minimum number of objective calls required, different initial sampling methods, and other ways to make \gls{hpo} more suitable for online use. The second possibility for future work to optimize the \gls{hpo} process is the evaluation of different solution scoring functions $f(\mathbf{\lambda})$, which could strongly influence what kind of \enquote{good} solutions are found. This is also where the lack of dynamic performance can be remedied, by including the correct detection of dynamic events in the evaluation function that gives feedback to \gls{hpo}. Implementing the precision and recall metrics described above in the function would be one way to do this.

\subsection{A Machine Learning Model For Parameter Inference}

The data sets obtained from the experiments for this thesis hold a very interesting possibility that could eventually replace \gls{hpo} in providing well-performing parameter values. What we have obtained from these repeated optimizer runs are hundreds of parameter sets that produce solutions close to the optimum. What we also obtained is the meta-information of each run, the problem instance, its detailed city placement properties, and the details describing the dynamic aspects. The work presented here has shown that the problem description has a huge influence on the parameters required to solve it optimally, and can therefore be understood as the most important factor in the choice of these parameters. However, direct correlations between parameter values and problems could not be observed, and seem to be of higher order. Thus, these higher-order relationships between the problem description and the resulting solution quality could be learned by a \gls{ml} model. It is capable of learning exactly these complex relationships that are not apparent by simple analysis.

The training set would consist of the the experimental data, especially the results of the second part. The input features $X$ are represented by the meta-information about the problem environment. The individual features $x_i$ should be easy to calculate on any \gls{dtsp} instance. Therefore, the statistical measures for problem instances (see \cref{chap:prob-stat-meas}) or a subset of only $R$, $\lambda_1$, and \gls{cqv} can be chosen as features describing the instance itself. The description of the dynamics can either be taken directly from this realization of swapping cities (e.g., the dynamic intensity $C$), or by formulating more general categories such as the percentage of cities affected (which in this case is equal to $C$), or a percentage of iterations with dynamic events (which can be calculated from the dynamic period $T_d$).
The output or label $Y$ is then the set of parameters chosen for that particular problem description.

With the formulated training data, there are two possible approaches: supervised learning using only the best parameter sets, or reinforcement learning also using the poorly performing parameter sets to further reinforce the good parameter sets.
The supervised learning method has the major disadvantage that it can only use a fraction of the \gls{hpo} data. In the case of 60 \texttt{n\_calls} only one parameter set from this run could be used. Therefore, it would be advisable to collect more training data by increasing the number of repeated optimizer runs and vary the problem descriptions. However, the mapping between the input parameters $X$ and the resulting good parameter sets $Y$ is easier to preprocess, and also easier to implement. This approach can also produce satisfactory accuracy with simple supervised learning methods, such as support-vector machines or logistic regression. 
In contrast, in the reinforcement learning training setup, the model learns the parameters based on the input features and the current state, which is the solution quality or score, in order to maximize a reward signal. A reward function must be defined that takes into account both the parameter sets and the solution quality. This approach requires more data and potentially more training time compared to supervised learning, but could lead to better accuracy and especially better generalization performance. 

Despite the \gls{ml} method chosen, inference on the trained model would then just take any problem description of a \gls{tsp} instance and output an optimal set of parameter values. However, since the training was done on data obtained with \gls{hsppbo}, the inferred parameter sets would also be limited to application to this metaheuristic.
